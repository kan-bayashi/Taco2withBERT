<!DOCTYPE html>
<html>
  <head>
	<meta name="generator" content="Hugo 0.54.0" />
    
    
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
  Pre-trained Text Embeddings for Enhanced Text-to-Speech Synthesis &ndash; Pre-trained Text Embeddings for Enhanced Text-to-Speech Synthesis

    </title>
    
    
    <meta name="description" property="og:description" content="">
    

    <meta name="apple-mobile-web-app-title" content="Pre-trained Text Embeddings for Enhanced Text-to-Speech Synthesis">
    
    
    
    


    <link rel="stylesheet" href="/Taco2withBERT/assets/syntax.css">
    <link rel="stylesheet" href="/Taco2withBERT/assets/primer-build.css">
    <link rel="stylesheet" href="/Taco2withBERT/assets/style.css">
  </head>


  <body class="bg-gray">
    <div id="holy" class="container-lg bg-white h-100">

      <div id="header" class="px-1 bg-white">
        <nav class="UnderlineNav UnderlineNav--right px-2">
  <a class="UnderlineNav-actions muted-link h2" href="https://kan-bayashi.github.io/Taco2withBERT/">
    Pre-trained Text Embeddings for Enhanced Text-to-Speech Synthesis
  </a>

  
  
</nav>

      </div>

      <div role="main" id="main" class="holy-main markdown-body px-4 bg-white">
        

<div>

  <h1>Pre-trained Text Embeddings for Enhanced Text-to-Speech Synthesis</h1>
  

  
  <div>
    <div>
      <a href="/Taco2withBERT/">
        <h3></h3>
      </a>
      <small>https://kan-bayashi.github.io/Taco2withBERT/</small>
      2019-07-01
    </div>
    Abstract We propose an end-to-end text-to-speech (TTS) synthesis model that explicitly uses information from pre-trained embeddings of the text. Recent work in natural language processing has developed self-supervised representations of text that have proven very effective as pre-training for language understanding tasks. We propose using one such pre-trained representation (BERT) to encode input phrases, as an additional input to a Tacotron2-based sequence-to-sequence TTS model. We hypothesize that the text embeddings contain information about the semantics of the phrase and the importance of each word, which should help TTS systems produce more natural prosody and pronunciation.
  </div>
  

  


</div>


      </div>

      <div id="side" class="pr-1 bg-white">
        <aside class="pr-3">
          
          <div id="toc" class="mb-3">
          </div>
          
        </aside>
      </div>

      <div id="footer" class="pt-2 pb-3 bg-white text-center">
        

  <span class="text-small text-gray">
    

    Powered by the
    <a href="https://github.com/qqhann/hugo-primer" class="link-gray-dark">Hugo-Primer</a> theme for
    <a href="https://gohugo.io" class="link-gray-dark">Hugo</a>.
  </span>


      </div>
    </div>


    
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });</script>
  </body>
</html>
